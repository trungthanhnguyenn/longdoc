"""
Document Write Agent for RAG-based content generation and report writing.

This agent uses RAG (Retrieval-Augmented Generation) to answer questions
generated by the Read Agent and writes structured content for each section.
"""

import json
import os
import uuid
import requests
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime
import logging

from langchain.schema import HumanMessage, SystemMessage
from langchain_community.chat_models import ChatOpenAI
from langchain_community.callbacks.manager import get_openai_callback

from src.base.manager import BaseModelManager
from src.config.config import LLMAgentConfig, ReportSkeleton, DocumentSection
from src.qdrant import QdrantManager
from src.qdrant.client import QdrantClient, SearchParams
from src.documents.embedding import Embedding
from src.config.config import APIConfig


class DocumentWriteAgent(BaseModelManager):
    """
    Agent for writing report content using RAG and structured generation.
    
    Retrieves relevant information using RAG with reranking to answer questions from the
    Read Agent and generates coherent content for each report section.
    """
    
    def _get_default_config(self):
        """Get default configuration for the agent."""
        return LLMAgentConfig.from_env()
    
    def _initialize(self, **kwargs) -> None:
        """Initialize agent components."""
        # Initialize LLM for content generation
        self.llm = ChatOpenAI(
            model_name=self.config.model_name,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
            top_p=self.config.top_p,
            openai_api_base=os.getenv('OPENAI_BASE_URL'),
            openai_api_key=os.getenv('OPENAI_API_KEY')
        )
        
        # Initialize Qdrant manager
        self.qdrant_manager = QdrantManager(kwargs.get('qdrant_config'))
        
        # Initialize embedding API for RAG
        self.embedding_api = Embedding(APIConfig.from_env())
        
        # Statistics
        self.written_sections = 0
        self.answered_questions = 0
        self.rag_queries = 0
        self.rerank_requests = 0
        
        # Set logging level to DEBUG for more detailed output
        self.logger.setLevel(logging.DEBUG)
        
        self.logger.info(f"DocumentWriteAgent initialized with {self.config.model_name}")
    
    def write_section_content(
        self,
        section: DocumentSection,
        skeleton: ReportSkeleton,
        collection_name: str,
        context_limit: int = 5,
        **kwargs
    ) -> DocumentSection:
        """
        Write content for a specific section using RAG with reranking.
        
        Args:
            section: Document section to write content for
            skeleton: Complete report skeleton for context
            collection_name: Qdrant collection name to search
            context_limit: Maximum number of context chunks to retrieve after reranking
            **kwargs: Additional writing options
            
        Returns:
            DocumentSection with generated content
        """
        try:
            self.logger.info(f"Writing content for section: {section.title}")
            
            # Get questions for this section
            section_questions = self._get_section_questions(section, skeleton)
            
            if not section_questions:
                self.logger.warning(f"No questions found for section: {section.title}")
                return section
            
            # Process all questions for this section at once
            content = self._answer_section_questions_with_rag(
                section_questions, section.title, collection_name, context_limit
            )
            
            # Update section with generated content
            section.content = content
            self.written_sections += 1
            self.answered_questions += len(section_questions)
            
            self.logger.info(f"Successfully wrote content for section: {section.title} "
                           f"({len(content)} characters, {len(section_questions)} questions answered)")
            
            return section
            
        except Exception as e:
            self.logger.error(f"Error writing content for section {section.title}: {e}")
            raise
    
    def write_complete_report(
        self,
        skeleton: ReportSkeleton,
        collection_name: str,
        context_limit: int = 5,
        output_filename: Optional[str] = None,
        **kwargs
    ) -> ReportSkeleton:
        """
        Write complete report by generating content for all sections.
        
        Args:
            skeleton: Report skeleton with sections and questions
            collection_name: Qdrant collection name to search
            context_limit: Maximum number of context chunks to retrieve per query
            output_filename: Optional custom filename for the output markdown file
            **kwargs: Additional writing options
            
        Returns:
            Complete ReportSkeleton with generated content
        """
        self.logger.info(f"Starting complete report generation: {skeleton.title}")
        
        # Sort sections by order
        sorted_sections = sorted(skeleton.main_sections, key=lambda x: x.order)
        
        # Write content for each section
        for i, section in enumerate(sorted_sections):
            self.logger.info(f"Writing section {i+1}/{len(sorted_sections)}: {section.title}")
            
            try:
                updated_section = self.write_section_content(
                    section=section,
                    skeleton=skeleton,
                    collection_name=collection_name,
                    context_limit=context_limit,
                    **kwargs
                )
                
                # Update skeleton with written section
                for j, orig_section in enumerate(skeleton.main_sections):
                    if orig_section.section_id == updated_section.section_id:
                        skeleton.main_sections[j] = updated_section
                        break
                        
            except Exception as e:
                self.logger.error(f"Failed to write section {section.title}: {e}")
                if kwargs.get("fail_fast", False):
                    raise
                continue
        
        # Update skeleton timestamp
        skeleton.updated_at = datetime.now().isoformat()
        
        # Save report to markdown file
        self._save_report_to_markdown(skeleton, output_filename)
        
        self.logger.info(f"Completed report generation: {skeleton.title}")
        return skeleton
    
    def _get_section_questions(self, section: DocumentSection, skeleton: ReportSkeleton) -> List[str]:
        """Get all questions for a section and its sub-sections."""
        questions = section.questions.copy() if section.questions else []
        
        # Find sub-sections
        for other_section in skeleton.main_sections:
            if other_section.parent_section == section.section_id:
                if other_section.questions:
                    questions.extend(other_section.questions)
        
        return questions
    
    def _answer_section_questions_with_rag(
        self,
        questions: List[str],
        section_title: str,
        collection_name: str,
        context_limit: int = 5
    ) -> str:
        """
        Answer multiple questions for a section using comprehensive RAG.
        
        Args:
            questions: List of questions for the section
            section_title: Title of the section
            collection_name: Qdrant collection name
            context_limit: Maximum context chunks per question
            
        Returns:
            Generated content for the section
        """
        try:
            self.logger.info(f"Processing {len(questions)} questions for section: {section_title}")
            self.logger.info(f"Target collection name: {collection_name}")
            
            # Check if collection exists first - create new client for the specific collection
            from src.qdrant import QdrantManager
            temp_qdrant_manager = QdrantManager(self.qdrant_manager.config)
            temp_qdrant_manager.collection_name = collection_name  # Override collection name
            self.logger.info(f"Created temp QdrantManager with collection: {temp_qdrant_manager.collection_name}")
            
            collection_exists = temp_qdrant_manager.is_collection_exists(collection_name)
            self.logger.info(f"Collection {collection_name} exists: {collection_exists}")
            
            if not collection_exists:
                self.logger.error(f"Collection {collection_name} does not exist")
                return f"Collection {collection_name} không tồn tại."
            
            # Log collection stats for debugging
            try:
                stats = temp_qdrant_manager.get_collection_stats()
                self.logger.info(f"Collection stats for {collection_name}: {stats}")
            except Exception as e:
                self.logger.warning(f"Could not get collection stats: {e}")
            
            # Collect all relevant contexts for all questions
            all_contexts = []
            unique_context_texts = set()
            
            for question in questions:
                self.rag_queries += 1
                
                # Get query embedding
                query_embedding = self.embedding_api.get_query_embeddings(question)
                
                if not query_embedding:
                    self.logger.warning(f"Failed to get query embedding for: {question}")
                    continue
                
                # Search for relevant contexts
                qdrant_client = QdrantClient(temp_qdrant_manager.config)
                
                search_params = SearchParams(
                    vector=query_embedding,
                    limit=15,  # Get more contexts for comprehensive coverage
                    score_threshold=0.1,
                    with_payload=True,
                    with_vectors=False
                )
                
                self.logger.debug(f"Searching for question: {question}")
                self.logger.debug(f"Search params: limit={search_params.limit}, threshold={search_params.score_threshold}")
                
                search_results = qdrant_client.search_points(
                    collection_name=collection_name,
                    search_params=search_params
                )
                
                self.logger.info(f"Found {len(search_results)} results for question: {question}")
                
                # Log first few results for debugging
                for i, result in enumerate(search_results[:3]):
                    self.logger.debug(f"Result {i}: score={result.score:.3f}, has_text={result.payload and 'text' in result.payload}")
                    if result.payload and result.payload.get('text'):
                        text_preview = result.payload['text'][:100] + "..." if len(result.payload['text']) > 100 else result.payload['text']
                        self.logger.debug(f"Text preview: {text_preview}")
                
                # Add unique contexts
                for result in search_results:
                    if result.payload and result.payload.get('text'):
                        context_text = result.payload['text']
                        if context_text not in unique_context_texts:
                            unique_context_texts.add(context_text)
                            all_contexts.append({
                                'text': context_text,
                                'score': result.score,
                                'question': question
                            })
            
            if not all_contexts:
                self.logger.warning(f"No contexts found for section: {section_title}")
                return f"Không tìm thấy thông tin liên quan cho phần: {section_title}"
            
            self.logger.info(f"Found {len(all_contexts)} unique contexts for section: {section_title}")
            
            # Rerank all contexts if needed, or use top scored ones
            all_contexts.sort(key=lambda x: x['score'], reverse=True)
            top_contexts = all_contexts[:context_limit * 2]  # Take more for comprehensive coverage
            
            # Generate section content from all contexts
            return self._generate_section_content_from_contexts(
                section_title, questions, top_contexts
            )
            
        except Exception as e:
            self.logger.error(f"Error in section RAG processing: {e}")
            return f"Lỗi khi xử lý phần {section_title}: {str(e)}"
    
    def _generate_section_content_from_contexts(
        self,
        section_title: str,
        questions: List[str],
        contexts: List[Dict]
    ) -> str:
        """
        Generate section content from multiple contexts and questions.
        
        Args:
            section_title: Title of the section
            questions: List of questions to answer
            contexts: List of relevant contexts with scores
            
        Returns:
            Generated section content
        """
        try:
            # Prepare context text (deduplicated and sorted by relevance)
            context_texts = []
            for ctx in contexts:
                context_texts.append(f"[Relevance: {ctx['score']:.3f}] {ctx['text']}")
            
            combined_context = "\n\n".join(context_texts)
            
            # Create comprehensive prompt for section generation
            section_prompt = f"""
            Bạn đang viết nội dung cho phần "{section_title}" của một báo cáo phân tích tài liệu.
            
            CÁC CÂU HỎI CẦN TRẢ LỜI trong phần này:
            """
            
            for i, question in enumerate(questions, 1):
                section_prompt += f"{i}. {question}\n"
            
            section_prompt += f"""
            THÔNG TIN TÀI LIỆU LIÊN QUAN (đã được sắp xếp theo độ liên quan):
            {combined_context}  # Limit context length
            
            YÊU CẦU VIẾT NỘI DUNG:
            1. Viết một đoạn văn mạch lạc, có cấu trúc cho phần "{section_title}"
            2. Trả lời tất cả các câu hỏi được đề cập dựa trên thông tin tài liệu
            3. Tập trung vào thông tin có độ liên quan cao (score > 0.3)
            4. Viết theo văn phong báo cáo chuyên nghiệp, khách quan
            5. Chiều dài khoảng 300-800 từ tùy vào độ phức tạp
            6. Không thêm thông tin không có trong tài liệu
            7. Trích dẫn thông tin quan trọng một cách tự nhiên
            
            Hãy viết nội dung cho phần "{section_title}" ngay dưới đây:
            """
            
            with get_openai_callback() as cb:
                response = self.llm.generate([[SystemMessage(content="Bạn là một chuyên gia phân tích tài liệu và viết báo cáo kỹ thuật."), HumanMessage(content=section_prompt)]])
                self.logger.debug(f"Section content generation: {cb.total_tokens} tokens, ${cb.total_cost:.4f}")
            
            # Extract content with error handling
            try:
                content = response.generations[0][0].text.strip()
            except AttributeError:
                if hasattr(response, 'generations') and response.generations:
                    generation = response.generations[0][0]
                    if hasattr(generation, 'text'):
                        content = generation.text.strip()
                    else:
                        content = str(generation).strip()
                else:
                    content = str(response).strip()
            
            return content
            
        except Exception as e:
            self.logger.error(f"Error generating section content from contexts: {e}")
            return f"Lỗi khi tạo nội dung: {str(e)}"
    
    def _answer_question_with_enhanced_rag(
        self, 
        question: str, 
        collection_name: str, 
        context_limit: int = 5
    ) -> str:
        """
        Answer a question using enhanced RAG with reranking.
        
        Args:
            question: Question to answer
            collection_name: Qdrant collection name
            context_limit: Maximum number of context chunks to retrieve after reranking
            
        Returns:
            Generated answer based on retrieved context
        """
        try:
            self.logger.debug(f"Answering question with enhanced RAG + reranking: {question}")
            self.rag_queries += 1
            
            # Check if collection exists first
            if not self.qdrant_manager.is_collection_exists(collection_name):
                self.logger.error(f"Collection {collection_name} does not exist")
                return f"Collection {collection_name} không tồn tại."
            
            # Step 1: Get query embedding using the embedding API
            query_embedding = self.embedding_api.get_query_embeddings(question)
            
            if not query_embedding:
                self.logger.warning(f"Failed to get query embedding for: {question}")
                return "Không thể tạo embedding cho câu hỏi."
            
            # Step 2: Retrieve more documents (top 20) for reranking
            qdrant_client = QdrantClient(self.qdrant_manager.config)
            
            # Create search parameters (lower threshold to get more results)
            search_params = SearchParams(
                vector=query_embedding,
                limit=20,  # Retrieve more for reranking
                score_threshold=0.1,  # Lower threshold
                with_payload=True,
                with_vectors=False
            )
            
            search_results = qdrant_client.search_points(
                collection_name=collection_name,
                search_params=search_params
            )
            
            if not search_results:
                self.logger.warning(f"No relevant context found for question: {question}")
                # Try without threshold
                search_params_no_threshold = SearchParams(
                    vector=query_embedding,
                    limit=10,
                    score_threshold=None,
                    with_payload=True,
                    with_vectors=False
                )
                search_results = qdrant_client.search_points(
                    collection_name=collection_name,
                    search_params=search_params_no_threshold
                )
                
                if not search_results:
                    self.logger.warning(f"Still no results even without threshold for: {question}")
                    return "Không tìm thấy thông tin liên quan trong tài liệu."
            
            # Step 3: Prepare contexts for reranking
            contexts = []
            for result in search_results:
                payload = result.payload
                if payload and payload.get('text'):
                    contexts.append({
                        'id': result.id,
                        'text': payload['text'],
                        'score': result.score
                    })
            
            # Step 4: Rerank contexts using API
            reranked_contexts = self._rerank_contexts(question, contexts, top_k=context_limit)
            
            if not reranked_contexts:
                # Fallback to top contexts by original score
                reranked_contexts = [ctx['text'] for ctx in contexts[:context_limit]]
            
            # Step 5: Generate answer using reranked contexts
            context_text = "\n\n".join(reranked_contexts)
            
            answer_prompt = f"""
            Dựa trên thông tin tài liệu dưới đây, hãy trả lời câu hỏi một cách chính xác và đầy đủ.
            
            CÂU HỎI:
            {question}
            
            THÔNG TIN TÀI LIỆU (đã được sắp xếp theo mức độ liên quan):
            {context_text}
            
            Hãy trả lời câu hỏi dựa trên thông tin được cung cấp. Nếu thông tin không đủ để trả lời,
            hãy nêu rõ điều đó và đưa ra câu trả lời tốt nhất có thể dựa trên nội dung có sẵn.
            
            QUY TẮC TRẢ LỜI:
            1. Trả lời chính xác dựa trên nội dung tài liệu
            2. Nếu có nhiều thông tin liên quan, tổng hợp một cách logic
            3. Nêu rõ nguồn thông tin khi cần thiết
            4. Giữ văn phong chuyên nghiệp và khách quan
            """
            
            with get_openai_callback() as cb:
                response = self.llm.generate([[SystemMessage(content="Bạn là một trợ lý AI chuyên trích xuất và tóm tắt thông tin từ tài liệu."), HumanMessage(content=answer_prompt)]])
                self.logger.debug(f"RAG answer generation: {cb.total_tokens} tokens, ${cb.total_cost:.4f}")
            
            # Extract answer text with error handling
            try:
                answer = response.generations[0][0].text.strip()
            except AttributeError:
                # Handle different response structure
                if hasattr(response, 'generations') and response.generations:
                    generation = response.generations[0][0]
                    if hasattr(generation, 'text'):
                        answer = generation.text.strip()
                    else:
                        answer = str(generation).strip()
                else:
                    answer = str(response).strip()
            
            # Add source information
            if len(reranked_contexts) > 0:
                answer += f"\n\n(Nguồn: dựa trên {len(reranked_contexts)} đoạn văn bản liên quan nhất từ tài liệu)"
            
            return answer
            
        except Exception as e:
            self.logger.error(f"Error in enhanced RAG question answering: {e}")
            return f"Lỗi khi trả lời câu hỏi: {str(e)}"
    
    def _rerank_contexts(self, query: str, contexts: List[Dict], top_k: int = 5) -> List[str]:
        """
        Rerank contexts using the rerank API.
        
        Args:
            query: Query text
            contexts: List of context dictionaries with 'text' and 'score'
            top_k: Number of top contexts to return
            
        Returns:
            List of reranked context texts
        """
        try:
            if len(contexts) <= top_k:
                return [ctx['text'] for ctx in contexts]
            
            # Prepare rerank data
            rerank_data = {
                'query': query,
                'contexts': [ctx['text'] for ctx in contexts]
            }
            
            self.rerank_requests += 1
            
            rerank_response = requests.post(
                f"{self.embedding_api.api_url}/rerank",
                json=rerank_data,
                timeout=self.embedding_api.timeout
            )
            
            if rerank_response.status_code == 200:
                rerank_results = rerank_response.json()
                # Return top_k reranked contexts
                return [ctx['text'] for ctx in rerank_results[:top_k]]
            else:
                self.logger.warning(f"Rerank API failed with status {rerank_response.status_code}")
                # Fallback to top_k by original score
                sorted_contexts = sorted(contexts, key=lambda x: x['score'], reverse=True)
                return [ctx['text'] for ctx in sorted_contexts[:top_k]]
                
        except Exception as e:
            self.logger.error(f"Reranking error: {e}")
            # Fallback to top_k by original score
            sorted_contexts = sorted(contexts, key=lambda x: x['score'], reverse=True)
            return [ctx['text'] for ctx in sorted_contexts[:top_k]]
    
    def _generate_section_content(
        self,
        section: DocumentSection,
        question_answers: Dict[str, str],
        skeleton: ReportSkeleton
    ) -> str:
        """
        Generate coherent section content from question answers.
        
        Args:
            section: Section to generate content for
            question_answers: Dictionary of questions and their answers
            skeleton: Complete skeleton for context
            
        Returns:
            Generated section content
        """
        try:
            # Prepare content generation prompt
            content_prompt = f"""
            Bạn đang viết nội dung cho một phần của báo cáo. Dựa trên các câu trả lời cho các câu hỏi đã đặt ra,
            hãy tạo một đoạn văn bản mạch lạc, có cấu trúc cho phần này.
            
            THÔNG TIN PHẦN:
            - Tiêu đề: {section.title}
            - Mô tả: {section.description}
            
            CÂU HỎI VÀ TRẢ LỜI:
            """
            
            for question, answer in question_answers.items():
                content_prompt += f"""
            Q: {question}
            A: {answer}
            """
            
            content_prompt += f"""
            NGHỆ THUẬT VIẾT:
            1. Viết theo văn phong báo cáo chuyên nghiệp
            2. Tổ chức thông tin một cách logic, mạch lạc
            3. Bao gồm tất cả các thông tin quan trọng từ câu trả lời
            4. Đảm bảo tính liên kết giữa các ý
            5. Chiều dài khoảng 500-1000 từ tùy vào độ phức tạp của nội dung
            
            Hãy viết nội dung cho phần "{section.title}" ngay dưới đây:
            """
            
            with get_openai_callback() as cb:
                response = self.llm.generate([[SystemMessage(content="Bạn là một chuyên gia viết báo cáo kỹ thuật và phân tích tài liệu."), HumanMessage(content=content_prompt)]])
                self.logger.debug(f"Content generation: {cb.total_tokens} tokens, ${cb.total_cost:.4f}")
            
            # Extract content text with error handling
            try:
                content = response.generations[0][0].text.strip()
            except AttributeError:
                # Handle different response structure
                if hasattr(response, 'generations') and response.generations:
                    generation = response.generations[0][0]
                    if hasattr(generation, 'text'):
                        content = generation.text.strip()
                    else:
                        content = str(generation).strip()
                else:
                    content = str(response).strip()
            
            # Post-process content
            content = self._post_process_content(content, section)
            
            return content
            
        except Exception as e:
            self.logger.error(f"Error generating section content: {e}")
            return f"Lỗi khi tạo nội dung: {str(e)}"
    
    def _post_process_content(self, content: str, section: DocumentSection) -> str:
        """Post-process generated content for better quality."""
        # Remove any extra whitespace
        content = " ".join(content.split())
        
        # Ensure proper paragraph structure
        if not content.endswith('\n'):
            content += '\n'
        
        # Add section header if not present
        if not content.startswith(section.title):
            content = f"**{section.title}**\n\n{content}"
        
        return content
    
    def _save_report_to_markdown(self, skeleton: ReportSkeleton, custom_filename: Optional[str] = None) -> str:
        """
        Save the generated report to a markdown file in the output folder.
        
        Args:
            skeleton: Complete report skeleton with content
            custom_filename: Optional custom filename (without extension)
            
        Returns:
            Path to the saved markdown file
        """
        try:
            # Create output directory if it doesn't exist
            output_dir = "./output"
            os.makedirs(output_dir, exist_ok=True)
            
            # Generate filename
            if custom_filename:
                # Use custom filename, ensure .md extension
                filename = custom_filename if custom_filename.endswith('.md') else f"{custom_filename}.md"
            else:
                # Generate filename based on report title and timestamp
                safe_title = "".join(c for c in skeleton.title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                safe_title = safe_title.replace(' ', '_')
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{safe_title}_{timestamp}.md"
            
            filepath = os.path.join(output_dir, filename)
            
            # Generate markdown content
            markdown_content = self._generate_markdown_content(skeleton)
            
            # Write to file
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            self.logger.info(f"Report saved to: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"Failed to save report to markdown: {e}")
            raise
    
    def _generate_markdown_content(self, skeleton: ReportSkeleton) -> str:
        """
        Generate markdown content from the report skeleton.
        
        Args:
            skeleton: Complete report skeleton with content
            
        Returns:
            Markdown formatted content
        """
        markdown_lines = []
        
        # Add header
        markdown_lines.append(f"# {skeleton.title}")
        markdown_lines.append("")
        markdown_lines.append(f"*Generated on: {skeleton.updated_at}*")
        markdown_lines.append(f"*Document ID: {skeleton.document_id}*")
        markdown_lines.append(f"*Version: {skeleton.version}*")
        markdown_lines.append("")
        
        # Add table of contents
        markdown_lines.append("## Table of Contents")
        markdown_lines.append("")
        for section in sorted(skeleton.main_sections, key=lambda x: x.order):
            markdown_lines.append(f"{section.order}. [{section.title}](#{section.title.lower().replace(' ', '-')})")
        markdown_lines.append("")
        
        # Add sections
        for section in sorted(skeleton.main_sections, key=lambda x: x.order):
            markdown_lines.append(f"## {section.order}. {section.title}")
            markdown_lines.append("")
            
            if section.description:
                markdown_lines.append(f"*{section.description}*")
                markdown_lines.append("")
            
            if section.content:
                # Clean up content - remove duplicate headers if any
                content = section.content
                if content.startswith(f"**{section.title}**"):
                    content = content[len(f"**{section.title}**"):].strip()
                markdown_lines.append(content)
                markdown_lines.append("")
            
            # Add sub-sections
            sub_sections = [s for s in skeleton.main_sections if s.parent_section == section.section_id]
            if sub_sections:
                for sub_section in sorted(sub_sections, key=lambda x: x.order):
                    markdown_lines.append(f"### {sub_section.title}")
                    markdown_lines.append("")
                    
                    if sub_section.description:
                        markdown_lines.append(f"*{sub_section.description}*")
                        markdown_lines.append("")
                    
                    if sub_section.content:
                        markdown_lines.append(sub_section.content)
                        markdown_lines.append("")
        
        # Add footer
        markdown_lines.append("---")
        markdown_lines.append("")
        markdown_lines.append("*This report was generated automatically using RAG (Retrieval-Augmented Generation) with reranking.*")
        markdown_lines.append(f"*Total sections: {len(skeleton.main_sections)}*")
        
        return "\n".join(markdown_lines)
    
    def regenerate_section(
        self,
        section_id: str,
        skeleton: ReportSkeleton,
        collection_name: str,
        additional_context: Optional[str] = None,
        **kwargs
    ) -> DocumentSection:
        """
        Regenerate content for a specific section with additional context.
        
        Args:
            section_id: ID of section to regenerate
            skeleton: Complete report skeleton
            collection_name: Qdrant collection name
            additional_context: Additional context to include
            **kwargs: Additional regeneration options
            
        Returns:
            Regenerated DocumentSection
        """
        # Find the section
        target_section = None
        for section in skeleton.main_sections:
            if section.section_id == section_id:
                target_section = section
                break
        
        if not target_section:
            raise ValueError(f"Section with ID {section_id} not found")
        
        self.logger.info(f"Regenerating content for section: {target_section.title}")
        
        # Add additional context to section description if provided
        if additional_context:
            target_section.description += f"\n\nAdditional context: {additional_context}"
        
        # Regenerate content
        return self.write_section_content(target_section, skeleton, collection_name, **kwargs)
    
    def validate_report_quality(self, skeleton: ReportSkeleton) -> Dict[str, Any]:
        """
        Validate the quality and completeness of the generated report.
        
        Args:
            skeleton: Complete report skeleton with content
            
        Returns:
            Quality assessment results
        """
        validation_results = {
            "total_sections": len(skeleton.main_sections),
            "sections_with_content": 0,
            "total_questions": 0,
            "answered_questions": 0,
            "quality_issues": [],
            "completeness_score": 0.0
        }
        
        total_word_count = 0
        
        for section in skeleton.main_sections:
            # Check content
            if section.content and len(section.content.strip()) > 100:
                validation_results["sections_with_content"] += 1
                total_word_count += len(section.content.split())
            else:
                validation_results["quality_issues"].append(
                    f"Section '{section.title}' has insufficient or no content"
                )
            
            # Count questions
            if section.questions:
                validation_results["total_questions"] += len(section.questions)
            
            # Find sub-sections
            for other_section in skeleton.main_sections:
                if other_section.parent_section == section.section_id:
                    if other_section.questions:
                        validation_results["total_questions"] += len(other_section.questions)
        
        # Calculate completeness
        if validation_results["total_sections"] > 0:
            content_ratio = validation_results["sections_with_content"] / validation_results["total_sections"]
            validation_results["completeness_score"] = content_ratio
        
        # Add word count
        validation_results["total_word_count"] = total_word_count
        
        return validation_results
    
    def health_check(self) -> Dict[str, Any]:
        """Perform health check of the agent."""
        try:
            # Test LLM connection
            test_response = self.llm.generate([[SystemMessage(content="You are a helpful assistant."), HumanMessage(content="Respond with 'OK' if you can read this.")]])
            
            # Extract health check response with error handling
            try:
                response_text = test_response.generations[0][0].text
            except AttributeError:
                # Handle different response structure
                if hasattr(test_response, 'generations') and test_response.generations:
                    generation = test_response.generations[0][0]
                    if hasattr(generation, 'text'):
                        response_text = generation.text
                    else:
                        response_text = str(generation)
                else:
                    response_text = str(test_response)
            
            llm_status = "healthy" if "OK" in response_text else "degraded"
            
            # Test embedding API connection
            api_status = "connected"
            try:
                self.embedding_api._validate_api_connection()
            except Exception as e:
                api_status = f"error: {e}"
            
            # Test Qdrant connection
            qdrant_status = "connected"
            try:
                self.qdrant_manager.health_check()
            except Exception as e:
                qdrant_status = f"error: {e}"
                
        except Exception as e:
            llm_status = f"error: {e}"
            api_status = "error"
            qdrant_status = "error"
        
        return {
            "agent": "healthy" if all(status == "healthy" or status == "connected" 
                                   for status in [llm_status, api_status, qdrant_status]) else "degraded",
            "components": {
                "llm": llm_status,
                "embedding_api": api_status,
                "qdrant": qdrant_status
            },
            "statistics": {
                "written_sections": self.written_sections,
                "answered_questions": self.answered_questions,
                "rag_queries": self.rag_queries,
                "rerank_requests": self.rerank_requests
            }
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get agent statistics."""
        return {
            "written_sections": self.written_sections,
            "answered_questions": self.answered_questions,
            "rag_queries": self.rag_queries,
            "rerank_requests": self.rerank_requests,
            "config": {
                "model_name": self.config.model_name,
                "temperature": self.config.temperature,
                "max_tokens": self.config.max_tokens
            }
        }